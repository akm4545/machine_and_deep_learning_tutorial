1. 분류 모델
예측뿐만 아니라 예측의 근거가 되는 확률을 출력할 수 있다
확률은 분류 모델이 얼마나 예측을 확신하는지 나타낸다

2. k-최근접 이웃 모델
확률 출력은 가능하지만 이웃한 샘플의 클래스 비율이므로 
항상 정해진 확률만 출력

3. 로지스틱 회귀
회귀 모델이 아닌 분류 모델 
선형 회귀처럼 선형 방정식 사용 
선형 회귀처럼 계산한 값을 그대로 출력하는 것이 아니라 
로지스틱 회귀는 이 값을 0 ~ 1 사이의 값으로 압축 
이 값을 마치 0 ~ 100% 사이의 확률로 이해할 수 있다

이진 분류에서는 하나의 선형 방정식을 훈련한다
이 방정식의 출력값을 시그모이드 함수에 통과시켜 0~1사이의 값을 만든다
이 값이 양성 클래스에 대한 확률이다 
음성 클래스의 확률은 1에서 양성 클래스의 확률을 빼면 된다

다중 분류일 경우에는 클래스 개수만큼 방정식을 훈련한다
그다음 각 방정식의 출력값을 소프트맥스 함수를 통과시켜 전체 클래스에 대한 합이 항상 1이 되도록 만든다
이 값을 각 클래스에 대한 확률로 이해할 수 있다.

4. 다중분류
타깃 클래스가 2개 이상인 분류 문제 
로지스틱 회귀는 다중 분류를 위해서 소프트맥스를 사용하여 클래스 예측

5. 시그모이드 함수
선형 방정식의 출력을 0과 1 사이의 값으로 압축하여 이진 분류를 위해 사용

6. 소프트맥스 함수
다중 분류에서 여러 선형 방정식의 출력 결과를 정규화하여 값이 1이 되도록 만든다

scikit-learn
1. LogisticRegression
선형 분류 알고리즘인 로지스틱 회귀를 위한 클래스
solver 매개변수에서 사용할 알고리즘을 선택할 수 있다 
기본값은 lbfgs이다 
사이킷런 0.17 버전에 추가된 sag는 확률적 평균 경사 하강법 알고리즘으로 특성과 샘플 수가 많을 때 
성능이 빠르고 좋다
사이킷런 0.19 버전에는 sag의 개선 버전은 saga가 추가되었다
penalty 매개변수에서 L2규제(릿지 방식)와 L1규제(라쏘 방식)를 선택할 수 있다 
기본값은 L2규제를 의미하는 l2이다
C 매개변수에서 규제의 강도를 제어한다 기본값으 1.0이며 값이 작을수록 규제가 강해진다

2. predict_proba() 
예측 확률을 반환한다
이진 분류의 경우에는 샘플마다 음성 클래스와 양성 클래스에 대한 확률을 반환한다
다중 분류의 경우에는 샘플마다 모든 클래스에 대한 확률을 반환한다

3. decision_function()
모델이 학습한 선형 방정식의 출력을 반환
이진 분류의 경우 양성 클래스의 확률이 반환된다
이 값이 0보다 크면 양성 클래스, 작거나 같으면 음성 클래스로 예측
다중 분류의 경우 각 클래스마다 선형 방정식을 계산한다
가장 큰 값의 클래스가 예측 클래스가 된다
