확률적 경사 하강법
훈련 세트에서 샘플 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘
샘플을 하나씩 사용하지 않고 여러 개를 사용하면 미니배치 경사 하강법이 된다
한 번에 전체 샘플을 사용하면 배치 경사 하강법이 된다
충분히 반복하여 훈련하면 훈련세트에서 높은 점수를 얻는 모델을 만들 수 있다
훈련을 반복할수록 모델이 훈련 세트에 점점 더 잘 맞게 되어 어느 순간 과대적합되고 
테스트 세트의 정확도가 줄어들음

손실 함수
확률적 경사 하강법이 최적화할 대상
대부분의 문제에 잘 맞는 손실 함수가 이미 정의되어 있다
이진 분류에는 로지스틱 회귀(또는 이진 크로스엔트로피) 손실 함수를 사용
다중 분류에는 크로스엔트로피 손실 함수를 사용
회귀 문제는 평균 제곱 오차 손실 함수를 사용

에포크
확률적 경사 하강법에서 전체 샘플을 모두 사용하는 한 번 반복을 의미
일반적으로 경사 하강법 알고리즘은 수십에서 수백 번의 에포크를 반복


scikit-learn
1. SGDClassifier
확률적 경사 하강법을 사용한 분류 모델을 만든다
loss 매개변수는 확률적 경사 하강법으로 최적화할 손실 함수를 지정
기본값은 서포트 벡터 머신을 위한 hinge 손실 함수
로지스틱 회귀를 위해서는 log로 지정한다

penalty 매개변수에서 규제의 종류를 지정할 수 있다
기본값은 L2규제를 위한 l2이다
L1규제를 적용하려면 l1로 지정한다
규제 강도는 alpha 매개변수에서 지정하며 기본값은 0.0001이다

max_iter 매개변수는 에포크 횟수를 지정한다 기본값은 1000이다
tol 매개변수는 반복을 멈출 조건이다 
n_iter_no_change 매개변수에서 지정한 에포크 동안 손실이 tol만큼 줄어들지 않으면 알고리즘 중단
tol 매개변수의 기본값은 0.001이고 n_iter_no_change 매개변수의 기본값은 5이다

2. SGDRegressor
확률적 경사 하강법을 사용한 회귀 모델을 만든다
loss 매개변수에서 손실 함수를 지정한다 
기본값은 제곱 오차를 나타내는 squared_loss 이다 
SGDClassifier에서 설명한 매개변수는 모두 SGDRegressor에서 동일하게 사용된다