# 합성곱(convolution)
# 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있다
# 7장에서 사용한 밀집층에는 뉴런마다 입력 개수만큼의 가중치가 있다
# 즉 모든 입력에 가중치를 곱한다

# 인공 신경망은 처음에 가중치와 절편을 랜덤하게 초기화한 다음 에포크를 반복하면서 
# 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다
# 이것이 모델 훈련이다

# 예를 들어 밀집층에 뉴런이 3개 있다면 출력은 3개가 된다
# 입력 개수에 상관없이 동일하다
# 패션 MNIST 이미지에 잇는 784개의 픽셀을 입력받는 은닉층의 뉴런 개수가 100개면 
# 뉴런마다 하나씩 출력도 100개가 된다

# 합성곱은 밀집층의 계산과 조금 다르다
# 입력 데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다
# 합성곱 층의 뉴런에 있는 가중치 개수는 하이퍼파라미터다

# 신경망 층의 뉴런을 그림으로 표현하면 서로 조밀하게 연결되어 있다
# 합성곱에서는 뉴런이 입력 위를 이동하면서 출력을 만들기 떄문에 이런 식으로 표현하기 어렵다
# 또 뉴런이라고 부르기도 어색하다

# 합성곱 신경망 (convolutional neural network, CNN)에서는 완전 연결 신경망과 달리
# 뉴런을 필터(filter)나 커널(kernel)이라고 부른다

# 완전 연결 신경망
# 완전 연결 층(밀집층)만 사용하여 만든 신경망을 완전 연결 신경망(밀집 신경망)이라고 부른다

# 합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것이다
# 입력이 2차원 배열이면 필터도 2차원이어야 한다
# 합성곱은 출력을 필터가 입력에 놓인 위치에 맞게 2차원으로 배치한다
# 합성곱 계산을 통해 얻은 출력을 특별히 특성 맵(feature map)이라고 부른다

# 뉴런 = 필터
# 가중치 = 커널
# 출력 = 특성 맵

# 밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서도 여러 개의 필터를 사용한다

# 밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층에 있는 필터의 가중치(커널)도 모두 다르다
# 같은 가중치를 가진 필터를 여러 개 사용할 이유가 없다

# 실제 계산은 밀집층과 동일하게 단순히 입력과 가중치를 곱하는 것이지만 2차원 형태를 유지하는 점이 다르다
# 또 입력보다 훨씬 작은 크기의 커널을 사용하고 입력 위를 이동하면서 2차원 특성 맵을 만든다
# 이렇게 2차원 구조를 그대로 사용하기 때문에 합성곱 신경망이 이미지 처리 분야에서 뛰어난 성능을
# 발휘한다