결정 트리 모델
예 / 아니오에 대한 질문을 이어나가면서 정답을 찾아 학습하는 알고리즘
특성을 더 추가하지 않고도 결정 트리의 성능이 로지스틱 회귀 모델보다 더 좋다
결정 트리는 깊이가 너무 깊지 않다면 비교적 설명하기 쉽다
머신러닝 모델을 종종 블랙박스와 같다고 말한다
실제로 모델의 계수나 절편이 왜 그렇게 학습되었는지 설명하기가 어렵다
이에 비해 결정 트리는 비교적 비전문가에게도 설명하기 쉬운 모델을 만든다
결정 트리는 많은 앙상블 학습 알고리즘의 기반이 된다
앙상블 학습은 신경망과 함께 가장 높은 성능을 내기 때문에 인기가 높은 알고리즘이다

불순도
결정 트리가 최적의 질문을 찾기 위한 기준 
사이킷런은 지니 불순도와 엔트로피 불순도를 제공

정보 이득
부모 노드와 자식 노드의 불순도 차이
결정 트리 알고리즘은 정보 이득이 최대화되도록 학습

가지치기
결정 트리는 제한 없이 성장하면 훈련 세트에 과대적합되기 쉽다
가지치기는 결정 트리의 성장을 제한하는 방법이다
사이킷런의 결정 트리 알고리즘은 여러 가지 가지치기 매개변수를 제공

특성 중요도
결정 트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타내느 값
특성 중요도를 계산할 수 있는 것이 결정 트리의 또다른 큰 장점이다

1. pandas
info()
데이어프레임의 요약된 정보를 출력
인덱스와 컬럼 타입을 출력하고 널이 아닌 값의 개수, 메모리 사용향을 제공 
vervose 매개변수의 기본값 True를 False로 바꾸면 각 열에 대한 정보를 출력하지 않는다

describe()
데이터프레임 열의 통계 값을 제공한다
수치형일 경우 최소, 최대, 평균, 표준편차와 사분위값 등이 출력
문자열 같은 객체 타입의 열은 가장 자주 등장하는 값과 횟수 등이 출력
precentiles 매개변수에서 백분위수를 지정 기본값은 [0.25, 0.5, 0.75]이다

2.scikit-learn
DecisionTreeClassifier
결정 트리 분류 클래스
criterion 매개변수는 불순도를 지정하며 기본값은 지니 불순도를 의미하는 gini
entropy를 선택하여 엔트로피 불순도를 사용할 수 있다
splitter 매개변수는 노드를 분할하는 전략을 선택
기본값은 best로 정보 이득이 최대가 되도록 분할 random이면 임의로 노드를 분할
max_depth는 트리가 성장할 최대 깊이를 지정 기본값은 None으로 리프 노드가 순수하거나 min_samples_split보다 샘플 개수가 적을 떄까지 성장
min_samples_split은 노드를 나누기 위한 최소 샘플 개수 기본값은 2
max_features 매개변수는 최적의 분할을 위해 탐색할 특성의 개수 지정 기본값은 None으로 모든 특성을 사용

plot_tree()
결정 트리 모델을 시각화 첫 번째 매개변수로 결정 트리 모델 객체를 전달
max_depth 매개변수로 나타낼 트리의 깊이를 지정 기본값은 None으로 모든 노드를 출력
feature_names 매개변수로 특성의 이름을 지정할 수 있다
filled 매개변수를 True로 지정하면 타기값에 따라 노드 안에 색을 채운다

