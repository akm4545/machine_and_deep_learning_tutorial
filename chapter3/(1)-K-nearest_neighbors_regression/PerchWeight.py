import numpy as np

# 농어의 무게와 길이 데이터
# 넘파이 배열
perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,
       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,
       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,
       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,
       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,
       44.0])
perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,
       1000.0])

# 데이터가 어떤 형태를 띠고 있는지 파악하기 위해 산점도 렌더링
import matplotlib.pyplot as plt

# 농어의 길이가 커짐에 따라 무게도 같이 늘어난다
plt.scatter(perch_length, perch_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()

# 훈련 세트와 테스트 세트 데이터 생성
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    perch_length, perch_weight, random_state=42
)

# 훈련 세트는 2차원 배열이여야 한다 
# 파이썬에서는 1차원 배열의 크기는 원소가 1개인 튜플로 나타낸다 
# 예를 들어 [1, 2, 3]의 크기는 (3, )이다
# 이를 2차원 배열로 만들기 위해 억지로 하나의 열을 추가하면 배열의 크기가 (3, 1)이 된다
# 배열을 나타내는 방식만 달라졌을 뿐 배열에 있는 원소의 개수는 동일하게 3개다

# 넘파이 배열은 크기를 바꿀 수 있는 reshape() 메서드 제공
# 예제
test_array = np.array([1, 2, 3, 4])
print(test_array.shape)
# 1차원 배열 4개의 원소 보유
# (4, )

# (2, 2) 크기의 2차원 배열로 변환
# 바꾸려는 배열의 크기를 지정할 수 있다
# 원본 배열에 있는 원소의 개수와 다르면 에러가 발생한다
test_array = test_array.reshape(2, 2)
print(test_array.shape)

# 넘파이는 배열의 크기를 자동으로 지정하는 기능도 제공
# 크기에 -1을 지정하면 나머지 원소 개수로 모두 채우라는 의미 (원소의 갯수를 몰라도 해당 원소의 갯수만큼 배열을 만들어준다)
# 원소가 하나인 2차원 배열이 만들어진다 [[a], [b], [c]]
train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)
print(train_input.shape, test_input.shape)

# 사이킷런에서 k-최근접 이웃 회귀 알고리즘을 구현한 클래스는 KNeighborsRegressor
# 회귀 모델 훈련
from sklearn.neighbors import KNeighborsRegressor

knr = KNeighborsRegressor()

# k-최근접 이웃 회귀 모델을 훈련
knr.fit(train_input, train_target)

# 테스트 세트의 점수 확인
print(knr.score(test_input, test_target))

# 해당 코드를 실행하면 0.9928... 으로 나온다
# 회귀에서는 정확한 숫자를 맞힌다는 것은 거의 불가능하다 예측하는 값이나 타깃 모두 임의의 수치기이 때문이다
# 회귀의 경우에는 조금 다른 값으로 평가하는 이 점수를 결정계수라고 부른다 또는 간단히 R²라고 부른다
# 이 값은 
# 각 샘플의 타깃과 예측한 값의 차이를 제곱하여 더한다 
# 그 다음 타깃과 타깃 평균의 차이를 제곱하여 더한 값으로 나눈다 
# 만약 타깃의 평균 정도를 예측하는 수준이라면(즉 분자와 분모가 비슷해져) R²는 0에 가까워지고 
# 예측이 타깃에 아주 가까워지면 (분자가 0에 가까워지기 때문에) 1에 가까운 값이 된다

# 사이킷런의 score() 메서드가 출력하는 값은 높을수록 좋다 

# 타깃과 예측한 값 사이의 차이를 구해 보면 어느 정도 예측이 벗어났는지 가늠하기 좋다 
# 사이킷런은 sklearn.metrics 패키지 아래 여러 가지 측정 도구를 제공한다
# 이 중 mean_absolute_error는 타깃과 예측의 절댓값 오차를 평균하여 반환한다
from sklearn.metrics import mean_absolute_error

# 테스트 세트에 대한 예측을 만든다
test_prediction = knr.predict(test_input)

# 테스트 세트에 대한 평균 절댓값 오차를 계산한다
mae = mean_absolute_error(test_target, test_prediction)
print(mae)

# 훈련 세트로 R² 점수 확인
# 과소적합 훈련모델
print(knr.score(train_input, train_target))

# 0.96.... 출력

# 과대적합
# 훈련 세트에서 점수가 굉장히 좋았는데 테스트 세트에서는 점수가 굉장히 나쁘다면 모델이 훈련 세트에 과대적합되었다고 말한다
# 훈련 세트에만 잘 맞는 모델이라 테스트 세트와 나중에 실전에 투입하여 새로운 샘플에 대한 예측을 만들 때 잘 동작하지 않을 것이다

# 과소적합
# 훈련세트보다 테스트 세트의 점수가 높거나 두 점수가 모두 너무 낮은 경우
# 모델이 너무 단순하여 훈련 세트에 적절히 훈련되지 않은 경우

# 훈련 세트와 테스트 세트의 점수를 비교했을 때 훈련 세트가 너무 높으면 과대적합 그 반대이거나 두 점수가 모두 낮으면 과소적합이다

# 과소적합의 또 다른 원인은 훈련 세트와 테스트 세트의 크기가 매우 작기 때문이다

# 과소적합을 해결하기 위해 모델을 조금 더 복잡하게 만들자
# 훈련 세트에 더 잘 맞게 만들면 테스트 세트의 점수는 조금 나아질 것이다
# k-최근접 이웃 알고리즘으로 모델을 더 복잡하게 만드는 방법은 이웃의 개수 k를 줄이는 것이다
# 이웃의 개수를 줄이면 훈련 세트에 있는 국지적인 패턴에 민감해지고 이웃의 개수를 늘리면 데이터 전반에 있는 일반적인 패턴을 따를 것이다

# 이웃의 개수를 3으로 설정
knr.n_neighbors = 3

# 모델 다시 훈련 
knr.fit(train_input, train_target)
print(knr.score(train_input, train_target))

# 0.98... R²점수가 나온다

# 테스트 세트 점수 확인
print(knr.score(test_input, test_target))

# 0.97... R²점수가 나온다

# 테스트 세트의 점수는 훈련 세트보다 낮아졌으므로 과소적합 문제가 해결되었다
# 또한 두 점수의 차이가 크지 않으므로 과대적합도 일어나지 않았다

# R²(결정계수 값) 점수는 1에 가까울 수록 좋다
# 정량적인 평가를 하고 싶다면 사이킷런에서 제공하는 다른 평가 도구를 사용할 수 있다
# 대표적으로 절댓값 오차가 있다

# 훈련 세트의 점수와 테스트 세트의 점수 차이가 크면 좋지 않다 
# 일반적으로 훈련 세트의 점수가 테스트 세트보다 조금 더 높다 
# 만약 테스트 세트의 점수가 너무 낮다면 모델이 훈련 세트에 과도하게 맞춰진 것이다 
