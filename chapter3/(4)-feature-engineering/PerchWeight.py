# 1개의 특성을 사용했을 때 선형 회귀 모델이 학습하는 것은 직선이다
# 2개의 특성을 사용하면 선형 회귀는 평면을 학습한다
# 특성이 2개면 타깃값과 함께 3차원 공간을 형성하고 선형 회귀 방정식 
# 타깃 = a * 특성1 + b * 특성2 + 절편은 평면이 된다
# 선형 회귀를 단순한 직선이나 평면으로 생각하여 성능이 무조건 낮다고 오해해서는 안된다
# 특성이 많은 고차원에서는 선형 회귀가 매우 복잡한 모델을 표현할 수 있다

# 이번에는 농어의 길이뿐만 아니라 농어의 높이와 두께도 함께 사용해서 학습
# 이전 절에서처럼 3개의 특성을 각각 제곱하여 추가
# 거기다가 각 특성을 서로 곱해서 또 다른 특성을 만든다 (농어 길어 * 농어 높이)
# 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업을 특성 공학(feature engineering) 이라고 부른다

# 판다스(pandas)는 유명한 데이터 분석 라이브러리다 
# 데이터프레임(dataframe)은 판다스의 핵심 데이터 구조
# 넘파이 배열과 비슷하게 다차원 배열을 다룰 수 있지만 훨씬 더 많은 기능을 제공 
# 데이터프레임은 넘파이 배열로 쉽게 바꿀 수 있다

# 판다스 데이터프레임을 만들기 위해 많이 사용하는 파일은 csv 파일이다
# 판다스의 read_csv() 함수에 주소를 넣으면 데이터를 읽어올 수 있다
# 그 뒤 to_numpy() 메서드를 사용해 넘파이 배열로 바꾼다
import pandas as pd # pd는 관례적으로 사용하는 판다스의 별칭

df = pd.read_csv('https://bit.ly/perch_csv_data')
perch_full = df.to_numpy()
print(perch_full)

# 타깃 데이터 
import numpy as np

perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,
       1000.0])

# perch_full과 perch_weight를 훈련 세트와 테스트 세트로 나눈다
from sklean.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    perch_full, perch_weight, random_state=42
)

# 사이킷런은 특성을 만들거나 전처리하기 위한 다양한 클래스를 제공한다
# 사이킷런에서는 이런 클래스를 변환기(transformer)
# 사이킷런의 모델 클래스에 일관된 fit(), score(), predict() 메서드가 있는 것처럼 변환기 클래스는 모두 fit(), transform() 메서드를 제공